{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hail workshop\n",
    "\n",
    "This notebook will introduce the following concepts:\n",
    "\n",
    " - Using Jupyter notebooks effectively\n",
    " - Loading genetic data into Hail\n",
    " - General-purpose data exploration functionality\n",
    " - Plotting functionality\n",
    " - Quality control of sequencing data\n",
    " - Running a Genome-Wide Association Study (GWAS)\n",
    " - Rare variant burden tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hail on Jupyter\n",
    "\n",
    "From https://jupyter.org: \n",
    "\n",
    "\"The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more.\"\n",
    "\n",
    "In the last year, the Jupyter development team [released Jupyter Lab](https://blog.jupyter.org/jupyterlab-is-ready-for-users-5a6f039b8906), an integrated environment for data, code, and visualizations. If you've used R Studio, this is the closest thing that works in Python (and many other languages!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why notebooks?\n",
    "\n",
    "Part of what we think is so exciting about Hail is that it has coincided with a larger shift in the data science community.\n",
    "\n",
    "Three years ago, most computational biologists at Broad analyzed genetic data using command-line tools, and took advantage of research compute clusters by explicitly using scheduling frameworks like LSF or Sun Grid Engine.\n",
    "\n",
    "Now, they have the option to use Hail in interactive Python notebooks backed by thousands of cores on public compute clouds like [Google Cloud](https://cloud.google.com/), [Amazon Web Services](https://aws.amazon.com/), or [Microsoft Azure](https://azure.microsoft.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running cells\n",
    "\n",
    "Evaluate cells using `SHIFT + ENTER`. Select the next cell and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hello, world')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modes\n",
    "\n",
    "Jupyter has two modes, a **navigation mode** and an **editor mode**.\n",
    "\n",
    "#### Navigation mode:\n",
    "\n",
    " - <font color=\"blue\"><strong>BLUE</strong></font> cell borders\n",
    " - `UP` / `DOWN` move between cells\n",
    " - `ENTER` while a cell is selected will move to **editing mode**.\n",
    " - Many letters are keyboard shortcuts! This is a common trap.\n",
    " \n",
    "#### Editor mode:\n",
    "\n",
    " - <font color=\"green\"><strong>GREEN</strong></font> cell borders\n",
    " - `UP` / `DOWN`/ move within cells before moving between cells.\n",
    " - `ESC` will return to **navigation mode**.\n",
    " - `SHIFT + ENTER` will evaluate a cell and return to **navigation mode**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell types\n",
    "\n",
    "There are several types of cells in Jupyter notebooks. The two you will see here are **Markdown** (text) and **Code**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a code cell\n",
    "my_variable = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is a markdown cell**, so even if something looks like code (as below), it won't get executed!\n",
    "\n",
    "my_variable += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common gotcha: a code cell turns into markdown\n",
    "\n",
    "This can happen if you are in **navigation mode** and hit the keyboard shortcut `m` while selecting a code cell.\n",
    "\n",
    "You can either navigate to `Cell > Cell Type > Code` through the top menu, or use the keyboard shortcut `y` to turn it back to code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips and tricks\n",
    "\n",
    "Keyboard shortcuts:\n",
    "\n",
    " - `SHIFT + ENTER` to evaluate a cell\n",
    " - `ESC` to return to navigation mode\n",
    " - `y` to turn a markdown cell into code\n",
    " - `m` to turn a code cell into markdown\n",
    " - `a` to add a new cell **above** the currently selected cell\n",
    " - `b` to add a new cell **below** the currently selected cell\n",
    " - `d, d` (repeated) to delete the currently selected cell\n",
    " - `TAB` to activate code completion\n",
    " \n",
    "To try this out, create a new cell below this one using `b`, and print `my_variable` by starting with `print(my` and pressing `TAB`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common gotcha: the state of your code seems wrong\n",
    "\n",
    "Jupyter makes it easy to get yourself into trouble by executing cells out-of-order, or multiple times.\n",
    "\n",
    "For example, if I declare `x`:\n",
    "\n",
    "```\n",
    "x = 5\n",
    "```\n",
    "\n",
    "Then have a cell that reads:\n",
    "\n",
    "```\n",
    "x += 1\n",
    "```\n",
    "\n",
    "And finally:\n",
    "\n",
    "```\n",
    "print(x)\n",
    "```\n",
    "\n",
    "If you execute these cells in order and once, I'll see the notebook print `6`. However, there is **nothing stopping you** from executing the middle cell ten times, printing `16`!\n",
    "\n",
    "### Solution\n",
    "\n",
    "If you get yourself into trouble into this way, the solution is to clear the kernel (Python process) and start again from the top.\n",
    "\n",
    "First, `Kernel > Restart & Clear Output > (accept dialog)`.\n",
    "\n",
    "Second, `Cell > Run all above`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up our Python environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to Hail, we import a few methods from the [bokeh](https://bokeh.pydata.org/en/latest/) plotting library. We'll see examples soon!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hail as hl\n",
    "from bokeh.io import output_notebook, show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we initialize Hail and set up Bokeh to display inline in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl.init()\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download public 1000 Genomes data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workshop materials are designed to work on a small (~20MB) downsampled chunk of the public 1000 Genomes dataset.\n",
    "\n",
    "You can run these same functions on your computer or on the cloud!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl.utils.get_1kg('data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to call command-line utilities from Jupyter by prefixing a line with a `!`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -1 data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Explore genetic data with Hail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data from VCF\n",
    "\n",
    "The [Variant Call Format (VCF)](https://en.wikipedia.org/wiki/Variant_Call_Format) is a common file format for representing genetic data collected on multiple individuals (samples).\n",
    "\n",
    "Hail's [import_vcf](https://hail.is/docs/0.2/methods/impex.html#hail.methods.import_vcf) function can read this format.\n",
    "\n",
    "However, VCF is a text format that is easy for humans but very bad for computers. The first thing we do is `write` to a Hail native file format, which is much faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl.import_vcf('data/1kg.vcf.bgz').write('data/1kg.mt', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read 1KG into Hail\n",
    "\n",
    "We represent genetic data as a Hail [MatrixTable](https://hail.is/docs/0.2/overview/matrix_table.html), and name our variable `mt` to indicate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = hl.read_matrix_table('data/1kg.mt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a `MatrixTable`?\n",
    "\n",
    "Let's describe it!\n",
    "\n",
    "The `describe` method prints the **schema**, that is, the fields in the dataset and their types.\n",
    "\n",
    "You can see:\n",
    " - **numeric** types:\n",
    "     - integers (`int32`, `int64`), e.g. `5`\n",
    "     - floating point numbers (`float32`, `float64`), e.g. `5.5` or `3e-8`\n",
    " - **strings** (`str`), e.g. `\"Foo\"`\n",
    " - **boolean** values  (`bool`) e.g. `True`\n",
    " - **collections**:\n",
    "     - arrays (`array`), e.g. `[1,1,2,3]`\n",
    "     - sets (`set`), e.g. `{1,3}`\n",
    "     - dictionaries (`dict`), e.g. `{'Foo': 5, 'Bar': 10}`\n",
    " - **genetic data types**:\n",
    "     - loci (`locus`), e.g. `[GRCh37] 1:10000` or `[GRCh38] chr1:10024`\n",
    "     - genotype calls (`call`), e.g. `0/2` or `1|0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `count`\n",
    "\n",
    "`MatrixTable.count` returns a tuple with the number of rows (variants) and number of columns (samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `show`\n",
    "\n",
    "There is no `mt.show()` method, but you can show individual fields like the sample ID, `s`, or the locus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.s.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.locus.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"brightred\"><strong>Exercise: </strong></font> show other fields\n",
    "\n",
    "You can see the names of fields above. `show()` the first few values for a few of them, making sure to include at least one **row field** and **at least one entry field**. Capitalization is important.\n",
    "\n",
    "To print fields inside the `info` structure, you must add another dot, e.g. `mt.info.AN`.\n",
    "\n",
    "What do you notice being printed alongside some of the fields?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hail has functions built for genetics\n",
    "\n",
    "For example, `hl.summarize_variants` prints useful statistics about the genetic variants in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl.summarize_variants(mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most of Hail's functionality is totally general-purpose!\n",
    "\n",
    "Functions like `summarize_variants` are built out of Hail's general-purpose data manipulation functionality. We can use Hail to ask arbitrary questions about the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mt.aggregate_rows(hl.agg.count_where(mt.alleles == ['A', 'T']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if we had flight data:\n",
    "\n",
    "```\n",
    "flight_data.aggregate(\n",
    "    hl.agg.count_where(flight_data.departure_city == 'Boston')\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `counter` aggregator makes it possible to see distributions of categorical data, like alleles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_counts = mt.aggregate_rows(\n",
    "    hl.array(hl.agg.counter(mt.alleles)))\n",
    "snp_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By sorting the result in Python, we can recover an interesting bit of biology..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(snp_counts,\n",
    "       key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"brightred\"><strong>Question: </strong></font> What is interesting about this distribution?\n",
    "\n",
    "### <font color=\"brightred\"><strong>Question: </strong></font> Why do the counts come in pairs?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A closer look at GQ\n",
    "\n",
    "The GQ field in our dataset is an interesting one to explore further, and we can use various pieces of Hail's functionality to do so.\n",
    "\n",
    "**GQ** stands for **Genotype Quality**, and reflects confidence in a genotype call. It is a non-negative **integer** truncated at 99, and is the **phred-scaled** probability of the second-most-likely genotype call.\n",
    "\n",
    "Phred-scaling a value is the following transformation:\n",
    "\n",
    "$\\quad Phred(x) = -10 * log_{10}(x)$\n",
    "\n",
    "#### Example:\n",
    "\n",
    "\n",
    "$\\quad p_{0/0} = 0.9899$\n",
    "\n",
    "$\\quad p_{0/1} = 0.01$\n",
    "\n",
    "$\\quad p_{1/1} = 0.001$\n",
    "\n",
    "In this case,\n",
    "\n",
    "$\\quad GQ = -10 * log_{10} (0.01) = 20$\n",
    "\n",
    "\n",
    "Higher GQ values indicate higher confidence. $GQ=10$ is 90% confidence, $GQ=20$ is 99% confidence, $GQ=30$ is 99.9% confidence, and so on."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### GQ in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mt.aggregate_entries(hl.agg.stats(mt.GQ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our equation above, the mean value indicates about 99.9% confidence. But it's not generally a good idea to draw conclusions just based on a mean and standard deviation...\n",
    "\n",
    "It is possible to build more complicated queries using small pieces. We can use `hl.agg.filter` to compute conditional statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.aggregate_entries(hl.agg.filter(mt.GT.is_het(),\n",
    "                                   hl.agg.stats(mt.GQ)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look at GQ at genotypes that are **not heterozygous**, we need add only one character (`~`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mt.aggregate_entries(hl.agg.filter(~mt.GT.is_het(), \n",
    "                                   hl.agg.stats(mt.GQ)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are often many ways to accomplish something in Hail. We could have done these both together (and more efficiently!) using `hl.agg.group_by`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.aggregate_entries(hl.agg.group_by(mt.GT, \n",
    "                                     hl.agg.stats(mt.GQ)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the best way to understand a distribution is to **look** at it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = hl.plot.histogram(\n",
    "    mt.GQ, \n",
    "    bins=100)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"brightred\"><strong>Exercise: </strong></font> What's going on here? Investigate!\n",
    "\n",
    "*Hint: try copying some of the cells above and looking at DP, the sequencing depth, as well as GQ. The ratio between the two may also be interesting...*\n",
    "\n",
    "*Hint: if you want to plot a filtered GQ distribution, you can use something like:*\n",
    "\n",
    "    p = hl.plot.histogram(mt.filter_entries(mt.GT.is_het()).GQ, bins=100)\n",
    "\n",
    "Remember that you can create a new cell using keyboard shortcuts `A` or `B` in **navigation mode**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Annotation and quality control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate sample information\n",
    "\n",
    "We're building toward a genome-wide association test in part 3, but we don't just need genetic data to do a GWAS -- we also need phenotype data! Luckily, our `hl.utils.get_1kg` function also downloaded some simulated phenotype data.\n",
    "\n",
    "This is a text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head data/1kg_annotations.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can import it as a [Hail Table](https://hail.is/docs/0.2/overview/table.html) with [hl.import_table](https://hail.is/docs/0.2/methods/impex.html?highlight=import_table#hail.methods.import_table).\n",
    "\n",
    "We call it \"sa\" for \"sample annotations\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = hl.import_table('data/1kg_annotations.txt', \n",
    "                      impute=True, \n",
    "                      key='Sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we can see the names and types of fields in the logging messages, we can also `describe` and `show` this table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add sample metadata into our 1KG `MatrixTable`\n",
    "\n",
    "It's short and easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.annotate_cols(pheno = sa[mt.s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's going on here?\n",
    "\n",
    "Understanding what's going on here is a bit more difficult. To understand, we need to understand a few pieces:\n",
    "\n",
    "#### 1. `annotate` methods\n",
    "\n",
    "In Hail, `annotate` methods refer to **adding new fields**. \n",
    "\n",
    " - `MatrixTable`'s `annotate_cols` adds new column fields.\n",
    " - `MatrixTable`'s `annotate_rows` adds new row fields.\n",
    " - `MatrixTable`'s `annotate_entries` adds new entry fields.\n",
    " - `Table`'s `annotate` adds new row fields.\n",
    "\n",
    "In the above cell, we are adding a new coluimn field called \"pheno\". This field should be the values in our table `sa` associated with the sample ID `s` in our `MatrixTable` - that is, this is performing a **join**.\n",
    "\n",
    "Python uses square brackets to look up values in dictionaries:\n",
    "\n",
    "    d = {'foo': 5, 'bar': 10}\n",
    "    d['foo']\n",
    "\n",
    "You should think of this in much the same way - for each column of `mt`, we are looking up the fields in `sa` using the sample ID `s`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"brightred\"><strong>Exercise: </strong></font> Query some of these column fields using `mt.aggregate_cols`.\n",
    "\n",
    "Some of the aggregators we used earlier:\n",
    " - `hl.agg.counter`\n",
    " - `hl.agg.stats`\n",
    " - `hl.agg.count_where`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample QC\n",
    "\n",
    "We'll start with examples of sample QC.\n",
    "\n",
    "Hail has the function [hl.sample_qc](https://hail.is/docs/0.2/methods/genetics.html#hail.methods.sample_qc) to compute a list of useful statistics about samples from sequencing data.\n",
    "\n",
    "**Click the link** above to see the documentation, which lists the fields and their descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = hl.sample_qc(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.sample_qc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = hl.plot.scatter(x=mt.sample_qc.r_het_hom_var,\n",
    "                    y=mt.sample_qc.call_rate)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"brightred\"><strong>Exercise: </strong></font> Plot some other fields!\n",
    "\n",
    "Modify the cell above. Remember `hl.plot.histogram` as well!\n",
    "\n",
    "If you want to start getting fancy, you can plot more complicated expressions -- the ratio between two fields, for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter columns using generated QC statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.filter_cols(mt.sample_qc.dp_stats.mean >= 4)\n",
    "mt = mt.filter_cols(mt.sample_qc.call_rate >= 0.97)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entry QC\n",
    "\n",
    "We explored GQ above, and analysts often set thresholds for GQ to filter entries (genotypes). Another useful metric is **allele read balance**.\n",
    "\n",
    "This value is defined by:\n",
    "\n",
    "$\\quad AB = \\dfrac{N_{alt}}{{N_{ref} + N_{alt}}}$\n",
    "\n",
    "Where $N_{ref}$ is the number of reference reads and $N_{alt}$ is the number of alternate reads.\n",
    "\n",
    "We want "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call rate before filtering\n",
    "mt.aggregate_entries(hl.agg.fraction(hl.is_defined(mt.GT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = mt.AD[1] / hl.sum(mt.AD)\n",
    "\n",
    "filter_condition_ab = (\n",
    "    hl.case()\n",
    "    .when(mt.GT.is_hom_ref(), ab <= 0.1)\n",
    "    .when(mt.GT.is_het(), (ab >= 0.25) & (ab <= 0.75))\n",
    "    .default(ab >= 0.9) # hom-var\n",
    ")\n",
    "\n",
    "mt = mt.filter_entries(filter_condition_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call rate after filtering\n",
    "mt.aggregate_entries(hl.agg.fraction(hl.is_defined(mt.GT)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant QC\n",
    "\n",
    "Hail has the function [hl.variant_qc](https://hail.is/docs/0.2/methods/genetics.html#hail.methods.variant_qc) to compute a list of useful statistics about **variants** from sequencing data.\n",
    "\n",
    "Once again, **Click the link** above to see the documentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = hl.variant_qc(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mt.variant_qc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.variant_qc.AF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rare sites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.filter_rows(hl.min(mt.variant_qc.AF) > 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove sites far from [Hardy-Weinberg equilbrium](https://en.wikipedia.org/wiki/Hardy%E2%80%93Weinberg_principle):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.filter_rows(mt.variant_qc.p_value_hwe > 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final variant and sample count\n",
    "mt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: GWAS!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A GWAS is an independent association test performed per variant of a genetic dataset. We use the same phenotype and covariates, but test the genotypes for each variant separately. \n",
    "\n",
    "In Hail, the method we use is [hl.linear_regression_rows](https://hail.is/docs/0.2/methods/stats.html#hail.methods.linear_regression_rows).\n",
    "\n",
    "We use the phenotype `CaffeineConsumption` as our dependent variable, the number of alternate alleles as our independent variable, and no covariates besides an intercept term (that's the `1.0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwas = hl.linear_regression_rows(y=mt.pheno.CaffeineConsumption, \n",
    "                                 x=mt.GT.n_alt_alleles(), \n",
    "                                 covariates=[1.0])\n",
    "gwas.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two of the plots that analysts generally produce are a [Manhattan plot](https://en.wikipedia.org/wiki/Manhattan_plot) and a [Q-Q plot](https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot).\n",
    "\n",
    "We'll start with the Manhattan plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = hl.plot.manhattan(gwas.p_value)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = hl.plot.qq(gwas.p_value)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confounded!\n",
    "\n",
    "The Q-Q plot indicates **extreme** inflation of p-values.\n",
    "\n",
    "If you've done a GWAS before, you've probably included a few other covariates -- age, sex, and principal components.\n",
    "\n",
    "Principal components are a measure of genetic ancestry, and can be used to control for [population stratification](https://en.wikipedia.org/wiki/Population_stratification).\n",
    "\n",
    "We can compute principal components with Hail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_eigenvalues, pca_scores, pca_loadings = hl.hwe_normalized_pca(mt.GT, compute_loadings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **eigenvalues** reflect the amount of variance explained by each principal component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **scores** are the principal components themselves, computed per sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_scores.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_scores.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **loadings** are the contributions to each component for each variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_loadings.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can **annotate** the principal components back onto `mt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.annotate_cols(pca = pca_scores[mt.s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal components measure ancestry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p = hl.plot.scatter(mt.pca.scores[0], \n",
    "                    mt.pca.scores[1],\n",
    "                    label=mt.pheno.SuperPopulation)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"brightred\"><strong>Question: </strong></font> Does your plot match your neighbors'?\n",
    "\n",
    "If not, how is it different?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control confounders and run another GWAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwas = hl.linear_regression_rows(\n",
    "    y=mt.pheno.CaffeineConsumption, \n",
    "    x=mt.GT.n_alt_alleles(),\n",
    "    covariates=[1.0, mt.pheno.isFemale, mt.pca.scores[0], mt.pca.scores[1], mt.pca.scores[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = hl.plot.qq(gwas.p_value)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = hl.plot.manhattan(gwas.p_value)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Burden tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GWAS is a great tool for finding associations between **common variants** and disease, but a GWAS can't hope to find associations between rare variants and disease. Even if we have sequencing data for 1,000,000 people, we won't have the statistical power to link a mutation found in only a few people to any disease.\n",
    "\n",
    "But rare variation has lots of information - especially because statistical genetic theory dictates that rarer variants have, on average, stronger effects on disease per allele.\n",
    "\n",
    "One possible strategy is to **group together rare variants with similar predicted consequence**. For example, we can group all variants that are predicted to knock out the function of each gene and test the variants for each gene as a group.\n",
    "\n",
    "We will be running a burden test on our common variant dataset to demonstrate the technical side, but we shouldn't hope to find anything here -- especially because we've only got 10,000 variants!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import gene data\n",
    "\n",
    "We start by importing data about genes.\n",
    "\n",
    "First, we need to download it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://storage.googleapis.com/hail-tutorial/ensembl_gene_annotations.txt -O data/ensembl_gene_annotations.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_ht = hl.import_table('data/ensembl_gene_annotations.txt', impute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_ht.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_ht.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an interval key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_ht = gene_ht.transmute(interval = hl.locus_interval(gene_ht['Chromosome'],\n",
    "                                                         gene_ht['Gene start'],\n",
    "                                                         gene_ht['Gene end']))\n",
    "gene_ht = gene_ht.key_by('interval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate variants using these intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.annotate_rows(gene_info = gene_ht[mt.locus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.gene_info.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate genotypes per gene\n",
    "\n",
    "There is no `hl.burden_test` function -- instead, a burden test is the composition of two modular pieces of Hail functionality:\n",
    "\n",
    " - `group_rows_by / aggregate`\n",
    " - `hl.linear_regression_rows`.\n",
    " \n",
    "While this might be a few more lines of code to write than `hl.burden_test`, it means that you can flexibly specify the genotype aggregation however you like. Using other tools , you may have a few ways to aggregate, but if you want to do something different you are out of luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burden_mt = (\n",
    "    mt\n",
    "    .group_rows_by(gene = mt.gene_info['Gene name'])\n",
    "    .aggregate(n_variants = hl.agg.count_where(mt.GT.n_alt_alleles() > 0))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burden_mt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is `burden_mt`?\n",
    "\n",
    "It is a **gene-by-sample** matrix (compare to `mt`, a **variant-by-sample** matrix).\n",
    "\n",
    "It has one row field, the `gene`.\n",
    "\n",
    "It has one entry field, `n_variants`.\n",
    "\n",
    "It has all the column fields from `mt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run linear regression per gene\n",
    "\n",
    "This should look familiar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burden_results = hl.linear_regression_rows(\n",
    "    y=burden_mt.pheno.CaffeineConsumption, \n",
    "    x=burden_mt.n_variants,\n",
    "    covariates=[1.0, \n",
    "                burden_mt.pheno.isFemale, \n",
    "                burden_mt.pca.scores[0], \n",
    "                burden_mt.pca.scores[1], \n",
    "                burden_mt.pca.scores[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorry, no `hl.plot.manhattan` for genes!\n",
    "\n",
    "Instead, we can sort by p-value and print:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burden_results.order_by(burden_results.p_value).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"brightred\"><strong>Exercise: </strong></font> Where along the genome can we find the top gene?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"brightred\"><strong>Statistics question: </strong></font> What is the significance threshold for a burden test?\n",
    "\n",
    "Is this top gene genome-wide significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "242px",
    "width": "283px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
